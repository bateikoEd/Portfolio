{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabular = pd.read_csv(\"tabular_data.csv\")\n",
    "df_hashed = pd.read_csv(\"hashed_feature.csv\")\n",
    "df_train_target = pd.read_csv(\"train.csv\")\n",
    "df_test_target = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7984b0a0e139cabadb5afc7756d473fb34d23819\n",
       "1         47904b3331202e9881d003ff449c2eabfbc75460\n",
       "2         a99c4b3af723874ddd85af322beea81b64437294\n",
       "3         4dce5381031a88aed6b12ef71b6f7c3148e7b3c8\n",
       "4         d62db721202cb6636887f450a7b77fa97db03b05\n",
       "                            ...                   \n",
       "266048    b800c944804d341038e06d26cf560562942069e9\n",
       "266049    442e9a74e42ad60348408428654a686c4ed222ee\n",
       "266050    ff3c67182640fdbd26d2273a87c3311f45c68ae2\n",
       "266051    95ea6c6f652cb29edc327a2449eb8115ebc6841e\n",
       "266052    5e5065e69ff338ad1ea7b533bfba891e432a4737\n",
       "Name: feature_50, Length: 266053, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hashed['feature_50']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.432017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.526552</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.397517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>130.0</td>\n",
       "      <td>229.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.359440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509598</td>\n",
       "      <td>180.0</td>\n",
       "      <td>231.78</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>142.0</td>\n",
       "      <td>183.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.101487</td>\n",
       "      <td>444.730391</td>\n",
       "      <td>307.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>20.014485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>85.0</td>\n",
       "      <td>155.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  period  feature_0  feature_1  feature_2   feature_3  feature_4  \\\n",
       "0   0       1      110.0       55.0   0.432017    0.000000     176.78   \n",
       "1   0       2      110.0      110.0   0.397517    0.000000     315.42   \n",
       "2   0       3      110.0       55.0   0.359440    0.000000     354.55   \n",
       "3   0       4      110.0       55.0   0.285707    0.000000     229.98   \n",
       "4   0       5      110.0       55.0   0.101487  444.730391     307.12   \n",
       "\n",
       "   feature_5  feature_6  feature_7  ...  feature_40  feature_41  feature_42  \\\n",
       "0        0.0   0.323712        NaN  ...        0.00           0    0.000000   \n",
       "1        0.0   0.316798        NaN  ...        0.00           0    0.000000   \n",
       "2        0.0   0.339188        NaN  ...        0.07           0    0.000000   \n",
       "3        0.0   0.415428        NaN  ...        0.00           0    0.000000   \n",
       "4        0.0   0.569670        NaN  ...        0.95           0   20.014485   \n",
       "\n",
       "   feature_43  feature_44  feature_45  feature_46  feature_47  feature_48  \\\n",
       "0         0.0        55.0         2.0    0.526552       145.0      133.28   \n",
       "1         0.0       110.0         1.0    0.481063       130.0      229.97   \n",
       "2         0.0        55.0         1.0    0.509598       180.0      231.78   \n",
       "3         0.0        55.0         0.0    0.680089       142.0      183.83   \n",
       "4         0.0        55.0         0.0    0.776175        85.0      155.83   \n",
       "\n",
       "   feature_49  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tabular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7984b0a0e139cabadb5afc7756d473fb34d23819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47904b3331202e9881d003ff449c2eabfbc75460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a99c4b3af723874ddd85af322beea81b64437294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4dce5381031a88aed6b12ef71b6f7c3148e7b3c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>d62db721202cb6636887f450a7b77fa97db03b05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                feature_50\n",
       "0   0  7984b0a0e139cabadb5afc7756d473fb34d23819\n",
       "1   0  47904b3331202e9881d003ff449c2eabfbc75460\n",
       "2   0  a99c4b3af723874ddd85af322beea81b64437294\n",
       "3   0  4dce5381031a88aed6b12ef71b6f7c3148e7b3c8\n",
       "4   0  d62db721202cb6636887f450a7b77fa97db03b05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hashed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   1       0\n",
       "2   2       1\n",
       "3   3       0\n",
       "4   4       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4085</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4086</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4087</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4088</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  score\n",
       "0  4084    NaN\n",
       "1  4085    NaN\n",
       "2  4086    NaN\n",
       "3  4087    NaN\n",
       "4  4088    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabular_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4517    1278\n",
       "3503     957\n",
       "3329     925\n",
       "4967     774\n",
       "1885     756\n",
       "        ... \n",
       "3208       1\n",
       "2145       1\n",
       "3679       1\n",
       "3601       1\n",
       "2226       1\n",
       "Name: id, Length: 5106, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hashed['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    5106\n",
       "11    5106\n",
       "10    5106\n",
       "9     5106\n",
       "8     5106\n",
       "7     5106\n",
       "6     5106\n",
       "5     5106\n",
       "4     5106\n",
       "3     5106\n",
       "2     5106\n",
       "1     5106\n",
       "Name: period, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12 equal periods\n",
    "df_tabular['period'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test sets IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[13,7.5])\n",
    "plt.boxplot([df_tabular['id'], df_hashed['id'], df_train_target['id'], df_test_target['id']],\n",
    "           labels=['df_tabular', 'df_hashed', 'df_train_target', 'df_test_target'])\n",
    "plt.title('IDs distribution over the data files')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDs \t from 0:4083\n",
      "Test IDs \t from 4084:5105\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train IDs \\t from {df_train_target['id'].min()}:{df_train_target['id'].max()}\")\n",
    "print(f\"Test IDs \\t from {df_test_target['id'].min()}:{df_test_target['id'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hashed_feature.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(min, max): (0, 1278)\n"
     ]
    }
   ],
   "source": [
    "hlen = []\n",
    "indexes = []\n",
    "for i in range(df_hashed['id'].shape[0]):\n",
    "    hlen.append(df_hashed[df_hashed['id'] == i].shape[0])\n",
    "    indexes.append(i)\n",
    "\n",
    "print(f'(min, max): {min(hlen), max(hlen)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1278"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlen[4517]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hlen).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6));\n",
    "plt.scatter(x = indexes , y = hlen);\n",
    "plt.xlabel('IDs');\n",
    "plt.ylabel('Amount hashes');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of unsued ids in the hashed_feature.csv that need to be cleaned up.\n",
    "\n",
    "Each ID has up to 1278 hash values disclosing many to many relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6));\n",
    "plt.boxplot(hlen[:5105]);\n",
    "plt.title('Amount of hashes per id in the range from 0 to 5105');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD5CAYAAADcDXXiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASCElEQVR4nO3da4xc513H8e8Pm6RNSxWHbIJrJ9hFbsCtgJYlSimgUhMSShTnTSVXFAwEWUKhlJuKo7yoeBGpXMRNpSArSWsgJLJCIFYLpcFcIqSSsOmNJG6wSyDZxo23REAFUlqnf17MMR22s97dmVnvzLPfjzQ65zznnDn/Y+/+5tlnzplJVSFJasvXrHcBkqTxM9wlqUGGuyQ1yHCXpAYZ7pLUIMNdkhq0ebkNktwF3ACcrqrX9rW/A/hp4Azwoap6V9d+K3Az8CLwM1X1l8sd49JLL60dO3YMdQKStFE9+uijn6+qmUHrlg134APAe4E/ONuQ5PuAvcC3VtULSS7r2ncD+4DXAK8E/irJq6vqxXMdYMeOHczNza3kXCRJnST/ttS6ZYdlquoh4PlFzT8FvKeqXui2Od217wXuraoXquop4CRw9VBVS5KGNuyY+6uB70nycJK/S/KdXfs24Jm+7ea7NknSebSSYZml9tsCXAN8J3AkyauADNh24OcbJDkAHAC48sorhyxDkjTIsD33eeD+6nkE+DJwadd+Rd9224FnBz1BVR2qqtmqmp2ZGfh+gCRpSMOG+58BbwZI8mrgAuDzwFFgX5ILk+wEdgGPjKNQSdLKreRSyHuANwGXJpkH3g3cBdyV5DHgi8D+6n285ONJjgBP0LtE8pblrpSRJI1fJuEjf2dnZ8tLISVpdZI8WlWzg9Z5h6okNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ1qItx3HPzQepcgSROliXCXJP1/hrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVo2XBPcleS0933pS5e94tJKsmlfW23JjmZ5Mkk1427YEnS8lbSc/8AcP3ixiRXANcCT/e17Qb2Aa/p9nlfkk1jqVSStGLLhntVPQQ8P2DVbwLvAvq/YXsvcG9VvVBVTwEngavHUagkaeWGGnNPciPw2ar65KJV24Bn+pbnuzZJ0nm0ebU7JLkIuA34gUGrB7TVgDaSHAAOAFx55ZWrLUOSdA7D9Ny/CdgJfDLJvwLbgY8l+QZ6PfUr+rbdDjw76Emq6lBVzVbV7MzMzBBlSJKWsupwr6p/qqrLqmpHVe2gF+ivr6rPAUeBfUkuTLIT2AU8MtaKJUnLWsmlkPcAHwWuSjKf5Oaltq2qx4EjwBPAh4FbqurFcRUrSVqZZcfcq+pty6zfsWj5duD20cqSJI3CO1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDVoJd+heleS00ke62v7tSSfTvKpJH+a5OK+dbcmOZnkySTXrVXhkqSlraTn/gHg+kVtDwKvrapvBf4ZuBUgyW5gH/Cabp/3Jdk0tmrPYcfBD52Pw0jSVFg23KvqIeD5RW0fqaoz3eI/ANu7+b3AvVX1QlU9BZwErh5jvZKkFRjHmPtPAH/RzW8DnulbN9+1fZUkB5LMJZlbWFgYQxmSpLNGCvcktwFngLvPNg3YrAbtW1WHqmq2qmZnZmZGKUOStMjmYXdMsh+4AdhTVWcDfB64om+z7cCzw5cnSRrGUD33JNcDvwTcWFX/07fqKLAvyYVJdgK7gEdGL1OStBoruRTyHuCjwFVJ5pPcDLwX+DrgwSSfSPL7AFX1OHAEeAL4MHBLVb24ZtUv4hUzktSz7LBMVb1tQPOd59j+duD2UYqSJI3GO1QlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQSv5mr27kpxO8lhf2yVJHkxyoptu6Vt3a5KTSZ5Mct1aFS5JWtpKeu4fAK5f1HYQOFZVu4Bj3TJJdgP7gNd0+7wvyaaxVStJWpFlw72qHgKeX9S8FzjczR8Gbuprv7eqXqiqp4CTwNVjqlWStELDjrlfXlWnALrpZV37NuCZvu3muzZJ0nk07jdUM6CtBm6YHEgyl2RuYWFhzGVI0sY2bLg/l2QrQDc93bXPA1f0bbcdeHbQE1TVoaqararZmZmZIcuQJA0ybLgfBfZ38/uBB/ra9yW5MMlOYBfwyGglSpJWa/NyGyS5B3gTcGmSeeDdwHuAI0luBp4G3gpQVY8nOQI8AZwBbqmqF9eodknSEpYN96p62xKr9iyx/e3A7aMUJUkajXeoSlKDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0EjhnuTnkjye5LEk9yR5SZJLkjyY5EQ33TKuYiVJKzN0uCfZBvwMMFtVrwU2AfuAg8CxqtoFHOuWJUnn0ajDMpuBlybZDFwEPAvsBQ536w8DN414DEnSKg0d7lX1WeDXgaeBU8B/VtVHgMur6lS3zSngsnEUKklauVGGZbbQ66XvBF4JvCzJ21ex/4Ekc0nmFhYWhi1DkjTAKMMy3w88VVULVfUl4H7gu4DnkmwF6KanB+1cVYeqaraqZmdmZkYoQ5K02Cjh/jRwTZKLkgTYAxwHjgL7u232Aw+MVqIkabU2D7tjVT2c5D7gY8AZ4OPAIeDlwJEkN9N7AXjrOAqVJK3c0OEOUFXvBt69qPkFer14SdI68Q5VSWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1KDmwn3HwQ+tdwmStO6aC3dJkuEuSU0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUEjhXuSi5Pcl+TTSY4neUOSS5I8mOREN90yrmIlSSszas/9t4EPV9U3A98GHAcOAseqahdwrFuWJJ1HQ4d7klcA3wvcCVBVX6yq/wD2Aoe7zQ4DN41apCRpdUbpub8KWADen+TjSe5I8jLg8qo6BdBNLxtDnZKkVRgl3DcDrwd+r6peB/w3qxiCSXIgyVySuYWFhRHKkCQtNkq4zwPzVfVwt3wfvbB/LslWgG56etDOVXWoqmaranZmZmaEMiRJiw0d7lX1OeCZJFd1TXuAJ4CjwP6ubT/wwEgVjsBvZZK0UW0ecf93AHcnuQD4F+DH6b1gHElyM/A08NYRjyFJWqWRwr2qPgHMDli1Z5TnlSSNxjtUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUJPh7p2pkja6JsNdkjY6w12SGmS4S1KDmg13x90lbWTNhrskbWSGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg0YO9ySbknw8yQe75UuSPJjkRDfdMnqZkqTVGEfP/Z3A8b7lg8CxqtoFHOuWJUnn0UjhnmQ78EPAHX3Ne4HD3fxh4KZRjiFJWr1Re+6/BbwL+HJf2+VVdQqgm142aMckB5LMJZlbWFgYsQxJUr+hwz3JDcDpqnp0mP2r6lBVzVbV7MzMzLBlSJIG2DzCvm8EbkzyFuAlwCuS/BHwXJKtVXUqyVbg9DgKlSSt3NA996q6taq2V9UOYB/w11X1duAosL/bbD/wwMhVjsAPEJO0Ea3Fde7vAa5NcgK4tluWJJ1HowzL/J+q+lvgb7v5fwf2jON5JUnD8Q5VSWqQ4S5JDTLcJalBhrskNchwl6QGbZhw93p3SRvJhgl3SdpIDHdJapDhLkkN2lDh7ri7pI1iQ4W7JG0UhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0NDhnuSKJH+T5HiSx5O8s2u/JMmDSU500y3jK1eStBKj9NzPAL9QVd8CXAPckmQ3cBA4VlW7gGPd8rry5iVJG83Q4V5Vp6rqY938F4DjwDZgL3C42+wwcNOoRUqSVmcsY+5JdgCvAx4GLq+qU9B7AQAuG8cxJEkrN3K4J3k58CfAz1bVf61ivwNJ5pLMLSwsjFrGUByukdSqkcI9ydfSC/a7q+r+rvm5JFu79VuB04P2rapDVTVbVbMzMzOjlCFJWmSUq2UC3Akcr6rf6Ft1FNjfze8HHhi+PEnSMEbpub8R+BHgzUk+0T3eArwHuDbJCeDabnlinB2KWTyVpJZsHnbHqvp7IEus3jPs80qSRrch71BdSW/dHr2kabYhw12SWme4r5A9eUnTxHCXpAYZ7vz/XvniHro9dknTyHCXpAYZ7h176JJaYrgPcK6g90VA0jQw3IdgwEuadIa7JDXIcB+RvXhJk8hwP4dhLos07CVNAsN9BQxsSdPGcJekBhnufcbVQz/XHa/jPI4kLcVwH9JyAb3aUDfwJY2T4T6C8/05NEs9vy8MkhYz3CWpQUN/zd5yklwP/DawCbijqibqu1TH6Xz0nO2dS1qNNem5J9kE/C7wg8Bu4G1Jdq/FsSZZ/5dwD/pC7v72QeuWm1+reifZNNQoTYK1Gpa5GjhZVf9SVV8E7gX2rtGxptK5wnvQi8JS+y5uW7zvUi8qSz3PuWpcbbCuxdVH63H8Uazmxrdh/o2lpaxVuG8Dnulbnu/aJEnnQapq/E+avBW4rqp+slv+EeDqqnpH3zYHgAPd4lXAk0Me7lLg8yOUu96sf/1Mc+1g/etpUmr/xqqaGbRird5QnQeu6FveDjzbv0FVHQIOjXqgJHNVNTvq86wX618/01w7WP96moba12pY5h+BXUl2JrkA2AccXaNjSZIWWZOee1WdSfLTwF/SuxTyrqp6fC2OJUn6amt2nXtV/Tnw52v1/H1GHtpZZ9a/fqa5drD+9TTxta/JG6qSpPXlxw9IUoOmOtyTXJ/kySQnkxxc73oWS3JFkr9JcjzJ40ne2bVfkuTBJCe66Za+fW7tzufJJNetX/VfkWRTko8n+WC3PBX1J7k4yX1JPt39H7xhWmrv6vm57ufmsST3JHnJJNef5K4kp5M81te26nqTfEeSf+rW/U6SrGP9v9b9/HwqyZ8muXhS6/8qVTWVD3pv1H4GeBVwAfBJYPd617Woxq3A67v5rwP+md7HMfwqcLBrPwj8Sje/uzuPC4Gd3fltmoDz+Hngj4EPdstTUT9wGPjJbv4C4OIpqn0b8BTw0m75CPBjk1w/8L3A64HH+tpWXS/wCPAGIMBfAD+4jvX/ALC5m/+VSa5/8WOae+4T/xEHVXWqqj7WzX8BOE7vl3YvveChm97Uze8F7q2qF6rqKeAkvfNcN0m2Az8E3NHXPPH1J3kFvV/WOwGq6otV9R9MQe19NgMvTbIZuIjevSITW39VPQQ8v6h5VfUm2Qq8oqo+Wr2k/IO+fdbUoPqr6iNVdaZb/Ad69+xMZP2LTXO4T9VHHCTZAbwOeBi4vKpOQe8FALis22wSz+m3gHcBX+5rm4b6XwUsAO/vhpTuSPIypqN2quqzwK8DTwOngP+sqo8wJfX3WW2927r5xe2T4Cfo9cRhCuqf5nAfNI41kZf+JHk58CfAz1bVf51r0wFt63ZOSW4ATlfVoyvdZUDbetW/md6f2L9XVa8D/pvesMBSJql2urHpvfT+5H8l8LIkbz/XLgPaJvL3obNUvRN5HkluA84Ad59tGrDZRNU/zeG+7EccTIIkX0sv2O+uqvu75ue6P9/opqe79kk7pzcCNyb5V3rDXm9O8kdMR/3zwHxVPdwt30cv7KehdoDvB56qqoWq+hJwP/BdTE/9Z6223nm+MvTR375ukuwHbgB+uBtqgSmof5rDfeI/4qB7l/xO4HhV/UbfqqPA/m5+P/BAX/u+JBcm2QnsovfmzLqoqlurantV7aD37/vXVfV2pqD+qvoc8EySq7qmPcATTEHtnaeBa5Jc1P0c7aH3ns201H/Wqurthm6+kOSa7rx/tG+f8y69Lx36JeDGqvqfvlWTX/96vIs7rgfwFnpXoHwGuG296xlQ33fT+5PsU8AnusdbgK8HjgEnuuklffvc1p3Pk6zTu+xLnMub+MrVMlNRP/DtwFz37/9nwJZpqb2r55eBTwOPAX9I78qMia0fuIfe+wNfoteDvXmYeoHZ7pw/A7yX7mbLdar/JL2x9bO/v78/qfUvfniHqiQ1aJqHZSRJSzDcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lq0P8CnZY6uEQ60MoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(hlen[:5105],bins=1278);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing ids that are not present in our training and test datat\n",
    "df_hash2 = df_hashed[df_hashed['id']<=5105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266053, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hash2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoder for hashes\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "\n",
    "# put mis value as random hash with same len\n",
    "df_hash2.loc[:, 'feature_50'] = df_hash2.loc[:, 'feature_50'].fillna(secrets.token_hex(nbytes=len(df_hash2['feature_50'][0])//2)) \n",
    "\n",
    "df_hash2['hs'] = le.fit_transform(df_hash2['feature_50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7984b0a0e139cabadb5afc7756d473fb34d23819</td>\n",
       "      <td>2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>47904b3331202e9881d003ff449c2eabfbc75460</td>\n",
       "      <td>1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a99c4b3af723874ddd85af322beea81b64437294</td>\n",
       "      <td>3315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4dce5381031a88aed6b12ef71b6f7c3148e7b3c8</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>d62db721202cb6636887f450a7b77fa97db03b05</td>\n",
       "      <td>4180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                feature_50    hs\n",
       "0   0  7984b0a0e139cabadb5afc7756d473fb34d23819  2367\n",
       "1   0  47904b3331202e9881d003ff449c2eabfbc75460  1404\n",
       "2   0  a99c4b3af723874ddd85af322beea81b64437294  3315\n",
       "3   0  4dce5381031a88aed6b12ef71b6f7c3148e7b3c8  1543\n",
       "4   0  d62db721202cb6636887f450a7b77fa97db03b05  4180"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hash2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266053, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hash2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataframe for storing the matrix\n",
    "df_new_tabular = pd.get_dummies(df_hash2, columns = ['hs']).groupby(['id'],as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hs_0</th>\n",
       "      <th>hs_1</th>\n",
       "      <th>hs_2</th>\n",
       "      <th>hs_3</th>\n",
       "      <th>hs_4</th>\n",
       "      <th>hs_5</th>\n",
       "      <th>hs_6</th>\n",
       "      <th>hs_7</th>\n",
       "      <th>hs_8</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_5000</th>\n",
       "      <th>hs_5001</th>\n",
       "      <th>hs_5002</th>\n",
       "      <th>hs_5003</th>\n",
       "      <th>hs_5004</th>\n",
       "      <th>hs_5005</th>\n",
       "      <th>hs_5006</th>\n",
       "      <th>hs_5007</th>\n",
       "      <th>hs_5008</th>\n",
       "      <th>hs_5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  hs_0  hs_1  hs_2  hs_3  hs_4  hs_5  hs_6  hs_7  hs_8  ...  hs_5000  \\\n",
       "0   0     0     0     0     0     0     0     0     0     0  ...        0   \n",
       "1   1     0     0     0     0     0     0     0     0     0  ...        0   \n",
       "2   2     0     0     0     0     0     0     0     0     0  ...        0   \n",
       "3   3     0     0     0     0     0     0     0     0     0  ...        0   \n",
       "4   4     0     0     0     0     0     0     0     0     0  ...        0   \n",
       "\n",
       "   hs_5001  hs_5002  hs_5003  hs_5004  hs_5005  hs_5006  hs_5007  hs_5008  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   hs_5009  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 5011 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_tabular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5106, 5011), (61272, 52))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_tabular.shape, df_tabular.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Imputting missing values in df_tab columns **feature_0:feature_49**\n",
    " - Adding hashed categorical variable data\n",
    " - Adding hashed variable data\n",
    " - Scaling the data\n",
    " - Split for train, test and sumbission datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imputing missing values in df_tabular feature_0 : feature_49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>feature_41</th>\n",
       "      <th>feature_42</th>\n",
       "      <th>feature_43</th>\n",
       "      <th>feature_44</th>\n",
       "      <th>feature_45</th>\n",
       "      <th>feature_46</th>\n",
       "      <th>feature_47</th>\n",
       "      <th>feature_48</th>\n",
       "      <th>feature_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.432017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>176.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.526552</td>\n",
       "      <td>145.0</td>\n",
       "      <td>133.28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.397517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>315.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481063</td>\n",
       "      <td>130.0</td>\n",
       "      <td>229.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.359440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509598</td>\n",
       "      <td>180.0</td>\n",
       "      <td>231.78</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680089</td>\n",
       "      <td>142.0</td>\n",
       "      <td>183.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.101487</td>\n",
       "      <td>444.730391</td>\n",
       "      <td>307.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "      <td>20.014485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>85.0</td>\n",
       "      <td>155.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61267</th>\n",
       "      <td>5105</td>\n",
       "      <td>8</td>\n",
       "      <td>110.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>95.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094381</td>\n",
       "      <td>221.85</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082128</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61268</th>\n",
       "      <td>5105</td>\n",
       "      <td>9</td>\n",
       "      <td>110.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105878</td>\n",
       "      <td>343.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077594</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61269</th>\n",
       "      <td>5105</td>\n",
       "      <td>10</td>\n",
       "      <td>110.0</td>\n",
       "      <td>106.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>259.33</td>\n",
       "      <td>...</td>\n",
       "      <td>8.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.109053</td>\n",
       "      <td>43.0</td>\n",
       "      <td>74.52</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61270</th>\n",
       "      <td>5105</td>\n",
       "      <td>11</td>\n",
       "      <td>110.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040810</td>\n",
       "      <td>222.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.101929</td>\n",
       "      <td>35.0</td>\n",
       "      <td>25.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61271</th>\n",
       "      <td>5105</td>\n",
       "      <td>12</td>\n",
       "      <td>110.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042272</td>\n",
       "      <td>285.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61272 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  period  feature_0  feature_1  feature_2   feature_3  feature_4  \\\n",
       "0         0       1      110.0       55.0   0.432017    0.000000     176.78   \n",
       "1         0       2      110.0      110.0   0.397517    0.000000     315.42   \n",
       "2         0       3      110.0       55.0   0.359440    0.000000     354.55   \n",
       "3         0       4      110.0       55.0   0.285707    0.000000     229.98   \n",
       "4         0       5      110.0       55.0   0.101487  444.730391     307.12   \n",
       "...     ...     ...        ...        ...        ...         ...        ...   \n",
       "61267  5105       8      110.0       77.0        NaN    0.000000      95.30   \n",
       "61268  5105       9      110.0       77.0        NaN    0.000000      61.87   \n",
       "61269  5105      10      110.0      106.5        NaN    0.000000      88.05   \n",
       "61270  5105      11      110.0       45.0        NaN    0.000000      98.40   \n",
       "61271  5105      12      110.0       35.0        NaN    0.000000      30.70   \n",
       "\n",
       "       feature_5  feature_6  feature_7  ...  feature_40  feature_41  \\\n",
       "0            0.0   0.323712        NaN  ...        0.00           0   \n",
       "1            0.0   0.316798        NaN  ...        0.00           0   \n",
       "2            0.0   0.339188        NaN  ...        0.07           0   \n",
       "3            0.0   0.415428        NaN  ...        0.00           0   \n",
       "4            0.0   0.569670        NaN  ...        0.95           0   \n",
       "...          ...        ...        ...  ...         ...         ...   \n",
       "61267        0.0   0.094381     221.85  ...       -0.00           0   \n",
       "61268        0.0   0.105878     343.22  ...        1.75           0   \n",
       "61269        0.0   0.040169     259.33  ...        8.27           0   \n",
       "61270        0.0   0.040810     222.00  ...        0.00           0   \n",
       "61271        0.0   0.042272     285.35  ...        0.00           0   \n",
       "\n",
       "       feature_42  feature_43  feature_44  feature_45  feature_46  feature_47  \\\n",
       "0        0.000000         0.0        55.0         2.0    0.526552       145.0   \n",
       "1        0.000000         0.0       110.0         1.0    0.481063       130.0   \n",
       "2        0.000000         0.0        55.0         1.0    0.509598       180.0   \n",
       "3        0.000000         0.0        55.0         0.0    0.680089       142.0   \n",
       "4       20.014485         0.0        55.0         0.0    0.776175        85.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "61267    0.000000         0.0        75.0         0.0    0.082128        43.0   \n",
       "61268    0.000000         0.0        75.0         0.0    0.077594        49.0   \n",
       "61269    0.000000         0.0        99.0         1.0    0.109053        43.0   \n",
       "61270    0.000000         0.0         0.0         0.0    0.101929        35.0   \n",
       "61271    0.000000         0.0         0.0         0.0         NaN        35.0   \n",
       "\n",
       "       feature_48  feature_49  \n",
       "0          133.28         0.0  \n",
       "1          229.97         0.0  \n",
       "2          231.78         0.0  \n",
       "3          183.83         0.0  \n",
       "4          155.83         0.0  \n",
       "...           ...         ...  \n",
       "61267       83.97         0.0  \n",
       "61268       48.02         0.0  \n",
       "61269       74.52         0.0  \n",
       "61270       25.83         0.0  \n",
       "61271       29.03         0.0  \n",
       "\n",
       "[61272 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e43867297186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'feature_24'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'feature_24'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_26'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'feature_49'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_tabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feature_26'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'feature_49'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             reduce_func=process_chunk)\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;31m# process_chunk modifies X in place. No return value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1622\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1623\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mprocess_chunk\u001b[0;34m(dist_chunk, start)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# receivers with all nan distances impute with mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0mall_nan_dist_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                 \u001b[0mall_nan_receivers_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceivers_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_nan_dist_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(missing_values=np.nan, n_neighbors=10)\n",
    "\n",
    "df_tabular.loc[:,'feature_0':'feature_24'] = df_tabular.loc[:,'feature_0':'feature_24'].fillna(np.nan)\n",
    "df_tabular.loc[:,'feature_26':'feature_49'] = df_tabular.loc[:,'feature_26':'feature_49'].fillna(np.nan)\n",
    "\n",
    "\n",
    "df_tabular.loc[:,'feature_0':'feature_24'] = imputer.fit_transform(df_tabular.loc[:,'feature_0':'feature_24'].values)\n",
    "df_tabular.loc[:,'feature_26':'feature_49'] = imputer.fit_transform(df_tabular.loc[:,'feature_26':'feature_49'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding hashed categorical variable data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabular = df_tabular.loc[:,'id':'feature_49'].groupby(['id'],as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dataframes\n",
    "df_final = pd.merge(df_tabular, \n",
    "                   df_new_tabular, \n",
    "                   on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tabular.shape, df_new_tabular.shape, df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying missing IDs. \n",
    "s1 = set(df_tabular['id'])\n",
    "s2 = set(df_new_tabular['id'])\n",
    "s1.difference(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not have missing id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = StandardScaler()\n",
    "df_final.loc[:, 'feature_0':] = feature_scaler.fit_transform(df_final.loc[:, 'feature_0':])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_5000</th>\n",
       "      <th>hs_5001</th>\n",
       "      <th>hs_5002</th>\n",
       "      <th>hs_5003</th>\n",
       "      <th>hs_5004</th>\n",
       "      <th>hs_5005</th>\n",
       "      <th>hs_5006</th>\n",
       "      <th>hs_5007</th>\n",
       "      <th>hs_5008</th>\n",
       "      <th>hs_5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.353201</td>\n",
       "      <td>-0.280289</td>\n",
       "      <td>-0.314478</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>-0.077514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.641223</td>\n",
       "      <td>-0.525548</td>\n",
       "      <td>0.376949</td>\n",
       "      <td>1.567607</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.493083</td>\n",
       "      <td>2.177529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>-1.156991</td>\n",
       "      <td>6.080558</td>\n",
       "      <td>-0.345008</td>\n",
       "      <td>-0.912134</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.234475</td>\n",
       "      <td>-1.006661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.092595</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>1.355297</td>\n",
       "      <td>0.456179</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.439602</td>\n",
       "      <td>1.117243</td>\n",
       "      <td>-0.099082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.514074</td>\n",
       "      <td>-0.424867</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>0.102199</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.354729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  period  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0   0      78  -0.226445  -0.353201  -0.280289  -0.314478   0.035050   \n",
       "1   1      78  -0.226445   0.641223  -0.525548   0.376949   1.567607   \n",
       "2   2      78   0.308958  -1.156991   6.080558  -0.345008  -0.912134   \n",
       "3   3      78  -0.092595   0.065784   1.355297   0.456179   0.003617   \n",
       "4   4      78  -0.226445   0.514074  -0.424867  -0.077865   0.102199   \n",
       "\n",
       "   feature_5  feature_6  feature_7  ...   hs_5000   hs_5001  hs_5002  \\\n",
       "0  -0.284355  -0.361698  -0.077514  ... -0.057797 -0.057797   -0.028   \n",
       "1  -0.284355  -0.493083   2.177529  ... -0.057797 -0.057797   -0.028   \n",
       "2  -0.284355   0.234475  -1.006661  ... -0.057797 -0.057797   -0.028   \n",
       "3   0.439602   1.117243  -0.099082  ... -0.057797 -0.057797   -0.028   \n",
       "4  -0.284355   0.417400   0.354729  ... -0.057797 -0.057797   -0.028   \n",
       "\n",
       "    hs_5003   hs_5004   hs_5005   hs_5006   hs_5007  hs_5008   hs_5009  \n",
       "0 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "1 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "2 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "3 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "\n",
       "[5 rows x 5061 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for train, test and sumbission datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_final[df_final['id'] <= df_train_target['id'].max()] # Train data without target variable\n",
    "Test = df_final[df_final['id'] > df_train_target['id'].max()] # Test data for the final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_5000</th>\n",
       "      <th>hs_5001</th>\n",
       "      <th>hs_5002</th>\n",
       "      <th>hs_5003</th>\n",
       "      <th>hs_5004</th>\n",
       "      <th>hs_5005</th>\n",
       "      <th>hs_5006</th>\n",
       "      <th>hs_5007</th>\n",
       "      <th>hs_5008</th>\n",
       "      <th>hs_5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.353201</td>\n",
       "      <td>-0.280289</td>\n",
       "      <td>-0.314478</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>-0.077514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.641223</td>\n",
       "      <td>-0.525548</td>\n",
       "      <td>0.376949</td>\n",
       "      <td>1.567607</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.493083</td>\n",
       "      <td>2.177529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>-1.156991</td>\n",
       "      <td>6.080558</td>\n",
       "      <td>-0.345008</td>\n",
       "      <td>-0.912134</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.234475</td>\n",
       "      <td>-1.006661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.092595</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>1.355297</td>\n",
       "      <td>0.456179</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.439602</td>\n",
       "      <td>1.117243</td>\n",
       "      <td>-0.099082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.514074</td>\n",
       "      <td>-0.424867</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>0.102199</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.354729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>4079</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.369236</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.667726</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.629725</td>\n",
       "      <td>-0.474156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>4080</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.491332</td>\n",
       "      <td>0.418533</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.837065</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.550722</td>\n",
       "      <td>-0.884776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>4081</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.656925</td>\n",
       "      <td>0.149247</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.841542</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.758474</td>\n",
       "      <td>-0.649100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>4082</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.535873</td>\n",
       "      <td>0.860113</td>\n",
       "      <td>-0.340951</td>\n",
       "      <td>8.212135</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.880868</td>\n",
       "      <td>2.263257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>4083</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>1.342284</td>\n",
       "      <td>-0.496278</td>\n",
       "      <td>5.207258</td>\n",
       "      <td>-0.532711</td>\n",
       "      <td>9.009076</td>\n",
       "      <td>0.128850</td>\n",
       "      <td>-0.523227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4084 rows Ã— 5061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  period  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0        0      78  -0.226445  -0.353201  -0.280289  -0.314478   0.035050   \n",
       "1        1      78  -0.226445   0.641223  -0.525548   0.376949   1.567607   \n",
       "2        2      78   0.308958  -1.156991   6.080558  -0.345008  -0.912134   \n",
       "3        3      78  -0.092595   0.065784   1.355297   0.456179   0.003617   \n",
       "4        4      78  -0.226445   0.514074  -0.424867  -0.077865   0.102199   \n",
       "...    ...     ...        ...        ...        ...        ...        ...   \n",
       "4079  4079      78  -0.226445  -0.369236  -0.022308  -0.345022  -0.667726   \n",
       "4080  4080      78  -0.226445  -0.491332   0.418533  -0.345022  -0.837065   \n",
       "4081  4081      78  -0.226445  -0.656925   0.149247  -0.345022  -0.841542   \n",
       "4082  4082      78  -0.226445  -0.535873   0.860113  -0.340951   8.212135   \n",
       "4083  4083      78  -0.226445   1.342284  -0.496278   5.207258  -0.532711   \n",
       "\n",
       "      feature_5  feature_6  feature_7  ...   hs_5000   hs_5001  hs_5002  \\\n",
       "0     -0.284355  -0.361698  -0.077514  ... -0.057797 -0.057797   -0.028   \n",
       "1     -0.284355  -0.493083   2.177529  ... -0.057797 -0.057797   -0.028   \n",
       "2     -0.284355   0.234475  -1.006661  ... -0.057797 -0.057797   -0.028   \n",
       "3      0.439602   1.117243  -0.099082  ... -0.057797 -0.057797   -0.028   \n",
       "4     -0.284355   0.417400   0.354729  ... -0.057797 -0.057797   -0.028   \n",
       "...         ...        ...        ...  ...       ...       ...      ...   \n",
       "4079  -0.284355  -0.629725  -0.474156  ... -0.057797 -0.057797   -0.028   \n",
       "4080  -0.284355  -0.550722  -0.884776  ... -0.057797 -0.057797   -0.028   \n",
       "4081  -0.284355  -0.758474  -0.649100  ... -0.057797 -0.057797   -0.028   \n",
       "4082  -0.284355  -0.880868   2.263257  ... -0.057797 -0.057797   -0.028   \n",
       "4083   9.009076   0.128850  -0.523227  ... -0.057797 -0.057797   -0.028   \n",
       "\n",
       "       hs_5003   hs_5004   hs_5005   hs_5006   hs_5007  hs_5008   hs_5009  \n",
       "0    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "1    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "2    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "3    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "...        ...       ...       ...       ...       ...      ...       ...  \n",
       "4079 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4080 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4081 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4082 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4083 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "\n",
       "[4084 rows x 5061 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_5000</th>\n",
       "      <th>hs_5001</th>\n",
       "      <th>hs_5002</th>\n",
       "      <th>hs_5003</th>\n",
       "      <th>hs_5004</th>\n",
       "      <th>hs_5005</th>\n",
       "      <th>hs_5006</th>\n",
       "      <th>hs_5007</th>\n",
       "      <th>hs_5008</th>\n",
       "      <th>hs_5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>4084</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.057639</td>\n",
       "      <td>-0.182898</td>\n",
       "      <td>-0.231789</td>\n",
       "      <td>-0.289298</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.697912</td>\n",
       "      <td>0.090041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>4085</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.119365</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>1.440646</td>\n",
       "      <td>1.026640</td>\n",
       "      <td>-0.139292</td>\n",
       "      <td>0.745697</td>\n",
       "      <td>2.091669</td>\n",
       "      <td>-0.164419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4086</th>\n",
       "      <td>4086</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.284352</td>\n",
       "      <td>-0.266185</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>1.848069</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.941795</td>\n",
       "      <td>3.812455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>4087</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.689118</td>\n",
       "      <td>-0.299956</td>\n",
       "      <td>-0.214785</td>\n",
       "      <td>-0.699104</td>\n",
       "      <td>-0.072731</td>\n",
       "      <td>0.582012</td>\n",
       "      <td>0.112037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>4088</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.486823</td>\n",
       "      <td>-0.496393</td>\n",
       "      <td>-0.057237</td>\n",
       "      <td>-0.419735</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.077698</td>\n",
       "      <td>-0.135744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5101</th>\n",
       "      <td>5101</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.089875</td>\n",
       "      <td>-0.206891</td>\n",
       "      <td>-0.326283</td>\n",
       "      <td>1.787824</td>\n",
       "      <td>-0.267115</td>\n",
       "      <td>-0.333810</td>\n",
       "      <td>2.798973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>7.779336</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>5102</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.089909</td>\n",
       "      <td>0.430126</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.442216</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.092498</td>\n",
       "      <td>-0.661534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>5103</td>\n",
       "      <td>78</td>\n",
       "      <td>0.576659</td>\n",
       "      <td>-0.864217</td>\n",
       "      <td>0.493071</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.598464</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.201381</td>\n",
       "      <td>-0.878665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>5104</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.015874</td>\n",
       "      <td>-0.514345</td>\n",
       "      <td>-0.242156</td>\n",
       "      <td>-0.759876</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.218782</td>\n",
       "      <td>-0.852756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>5105</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.146099</td>\n",
       "      <td>6.538737</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.734881</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.862583</td>\n",
       "      <td>-0.370294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows Ã— 5061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  period  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "4084  4084      78  -0.226445  -0.057639  -0.182898  -0.231789  -0.289298   \n",
       "4085  4085      78  -0.119365   0.010757   1.440646   1.026640  -0.139292   \n",
       "4086  4086      78  -0.226445  -0.284352  -0.266185  -0.345022   1.848069   \n",
       "4087  4087      78  -0.226445  -0.689118  -0.299956  -0.214785  -0.699104   \n",
       "4088  4088      78  -0.226445   0.486823  -0.496393  -0.057237  -0.419735   \n",
       "...    ...     ...        ...        ...        ...        ...        ...   \n",
       "5101  5101      78  -0.226445   0.089875  -0.206891  -0.326283   1.787824   \n",
       "5102  5102      78  -0.226445  -0.089909   0.430126  -0.345022  -0.442216   \n",
       "5103  5103      78   0.576659  -0.864217   0.493071  -0.345022  -0.598464   \n",
       "5104  5104      78  -0.226445  -0.015874  -0.514345  -0.242156  -0.759876   \n",
       "5105  5105      78  -0.226445  -0.146099   6.538737  -0.345022  -0.734881   \n",
       "\n",
       "      feature_5  feature_6  feature_7  ...   hs_5000   hs_5001  hs_5002  \\\n",
       "4084  -0.284355  -0.697912   0.090041  ... -0.057797 -0.057797   -0.028   \n",
       "4085   0.745697   2.091669  -0.164419  ... -0.057797 -0.057797   -0.028   \n",
       "4086  -0.284355  -0.941795   3.812455  ... -0.057797 -0.057797   -0.028   \n",
       "4087  -0.072731   0.582012   0.112037  ... -0.057797 -0.057797   -0.028   \n",
       "4088  -0.284355  -0.077698  -0.135744  ... -0.057797 -0.057797   -0.028   \n",
       "...         ...        ...        ...  ...       ...       ...      ...   \n",
       "5101  -0.267115  -0.333810   2.798973  ... -0.057797 -0.057797   -0.028   \n",
       "5102  -0.284355   0.092498  -0.661534  ... -0.057797 -0.057797   -0.028   \n",
       "5103  -0.284355   0.201381  -0.878665  ... -0.057797 -0.057797   -0.028   \n",
       "5104  -0.284355  -0.218782  -0.852756  ... -0.057797 -0.057797   -0.028   \n",
       "5105  -0.284355  -0.862583  -0.370294  ... -0.057797 -0.057797   -0.028   \n",
       "\n",
       "       hs_5003   hs_5004   hs_5005   hs_5006   hs_5007  hs_5008   hs_5009  \n",
       "4084 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4085 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4086 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4087 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4088 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "...        ...       ...       ...       ...       ...      ...       ...  \n",
       "5101 -0.013996 -0.091071  7.779336 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "5102 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "5103 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "5104 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "5105 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "\n",
       "[1022 rows x 5061 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 5061), (1022, 2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is one missing id in the test dataset that needs to be inserted on the final stage\n",
    "Test.shape, df_test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.merge(df_train_target, \n",
    "              X, \n",
    "              on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>period</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>...</th>\n",
       "      <th>hs_5000</th>\n",
       "      <th>hs_5001</th>\n",
       "      <th>hs_5002</th>\n",
       "      <th>hs_5003</th>\n",
       "      <th>hs_5004</th>\n",
       "      <th>hs_5005</th>\n",
       "      <th>hs_5006</th>\n",
       "      <th>hs_5007</th>\n",
       "      <th>hs_5008</th>\n",
       "      <th>hs_5009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.353201</td>\n",
       "      <td>-0.280289</td>\n",
       "      <td>-0.314478</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.361698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.641223</td>\n",
       "      <td>-0.525548</td>\n",
       "      <td>0.376949</td>\n",
       "      <td>1.567607</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.493083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0.308958</td>\n",
       "      <td>-1.156991</td>\n",
       "      <td>6.080558</td>\n",
       "      <td>-0.345008</td>\n",
       "      <td>-0.912134</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.234475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.092595</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>1.355297</td>\n",
       "      <td>0.456179</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.439602</td>\n",
       "      <td>1.117243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>0.514074</td>\n",
       "      <td>-0.424867</td>\n",
       "      <td>-0.077865</td>\n",
       "      <td>0.102199</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>4079</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.369236</td>\n",
       "      <td>-0.022308</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.667726</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.629725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>4080</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.491332</td>\n",
       "      <td>0.418533</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.837065</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.550722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>4081</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.656925</td>\n",
       "      <td>0.149247</td>\n",
       "      <td>-0.345022</td>\n",
       "      <td>-0.841542</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.758474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>4082</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>-0.535873</td>\n",
       "      <td>0.860113</td>\n",
       "      <td>-0.340951</td>\n",
       "      <td>8.212135</td>\n",
       "      <td>-0.284355</td>\n",
       "      <td>-0.880868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>4083</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>-0.226445</td>\n",
       "      <td>1.342284</td>\n",
       "      <td>-0.496278</td>\n",
       "      <td>5.207258</td>\n",
       "      <td>-0.532711</td>\n",
       "      <td>9.009076</td>\n",
       "      <td>0.128850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.013996</td>\n",
       "      <td>-0.091071</td>\n",
       "      <td>-0.128546</td>\n",
       "      <td>-0.057797</td>\n",
       "      <td>-0.095346</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.078156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4084 rows Ã— 5062 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target  period  feature_0  feature_1  feature_2  feature_3  \\\n",
       "0        0       0      78  -0.226445  -0.353201  -0.280289  -0.314478   \n",
       "1        1       0      78  -0.226445   0.641223  -0.525548   0.376949   \n",
       "2        2       1      78   0.308958  -1.156991   6.080558  -0.345008   \n",
       "3        3       0      78  -0.092595   0.065784   1.355297   0.456179   \n",
       "4        4       1      78  -0.226445   0.514074  -0.424867  -0.077865   \n",
       "...    ...     ...     ...        ...        ...        ...        ...   \n",
       "4079  4079       0      78  -0.226445  -0.369236  -0.022308  -0.345022   \n",
       "4080  4080       0      78  -0.226445  -0.491332   0.418533  -0.345022   \n",
       "4081  4081       0      78  -0.226445  -0.656925   0.149247  -0.345022   \n",
       "4082  4082       0      78  -0.226445  -0.535873   0.860113  -0.340951   \n",
       "4083  4083       0      78  -0.226445   1.342284  -0.496278   5.207258   \n",
       "\n",
       "      feature_4  feature_5  feature_6  ...   hs_5000   hs_5001  hs_5002  \\\n",
       "0      0.035050  -0.284355  -0.361698  ... -0.057797 -0.057797   -0.028   \n",
       "1      1.567607  -0.284355  -0.493083  ... -0.057797 -0.057797   -0.028   \n",
       "2     -0.912134  -0.284355   0.234475  ... -0.057797 -0.057797   -0.028   \n",
       "3      0.003617   0.439602   1.117243  ... -0.057797 -0.057797   -0.028   \n",
       "4      0.102199  -0.284355   0.417400  ... -0.057797 -0.057797   -0.028   \n",
       "...         ...        ...        ...  ...       ...       ...      ...   \n",
       "4079  -0.667726  -0.284355  -0.629725  ... -0.057797 -0.057797   -0.028   \n",
       "4080  -0.837065  -0.284355  -0.550722  ... -0.057797 -0.057797   -0.028   \n",
       "4081  -0.841542  -0.284355  -0.758474  ... -0.057797 -0.057797   -0.028   \n",
       "4082   8.212135  -0.284355  -0.880868  ... -0.057797 -0.057797   -0.028   \n",
       "4083  -0.532711   9.009076   0.128850  ... -0.057797 -0.057797   -0.028   \n",
       "\n",
       "       hs_5003   hs_5004   hs_5005   hs_5006   hs_5007  hs_5008   hs_5009  \n",
       "0    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "1    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "2    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "3    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4    -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "...        ...       ...       ...       ...       ...      ...       ...  \n",
       "4079 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4080 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4081 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4082 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "4083 -0.013996 -0.091071 -0.128546 -0.057797 -0.095346   -0.028 -0.078156  \n",
       "\n",
       "[4084 rows x 5062 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4084, 5061), (4084, 5062))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Xy['target']\n",
    "X = Xy.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the optimal model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, \\\n",
    "                            roc_auc_score , accuracy_score, precision_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(random_state=13, solver='saga', penalty='l1', class_weight=\"balanced\", max_iter=500)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DecTree', DecisionTreeClassifier())) \n",
    "models.append(('RF', RandomForestClassifier(n_estimators = 10))) \n",
    "models.append(('XGB', XGBClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR',\n",
       "  LogisticRegression(class_weight='balanced', max_iter=500, penalty='l1',\n",
       "                     random_state=13, solver='saga')),\n",
       " ('KNN', KNeighborsClassifier()),\n",
       " ('DecTree', DecisionTreeClassifier()),\n",
       " ('RF', RandomForestClassifier(n_estimators=10)),\n",
       " ('XGB',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                validate_parameters=None, verbosity=None))]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = []\n",
    "for mod , _ in models:\n",
    "    mod_list.append(mod)\n",
    "\n",
    "mod_list.append('Cleaning')\n",
    "\n",
    "df_boxplot = pd.DataFrame(columns=['Score', 'ML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR', 'KNN', 'DecTree', 'RF', 'XGB', 'Cleaning']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_for_model():\n",
    "    seed = 13\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'roc_auc'\n",
    "\n",
    "    for name, model in models:\n",
    "        strat = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "\n",
    "        cv_results = cross_val_score(model, X_train, y_train, cv=strat, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "\n",
    "        print(f\"{name}: {cv_results.mean()} ({cv_results.std()})\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.6940413476899654 (0.019564329043246415)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: 0.5213866948264586 (0.03860424321143812)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecTree: 0.5764630347966516 (0.02339222540210056)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.6748310072805439 (0.0297047264720119)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/anaconda3/envs/ml_coursera/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.714612830590559 (0.020260498206348315)\n"
     ]
    }
   ],
   "source": [
    "results = get_score_for_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_res_to_boxplot(results, df):\n",
    "    i = 0\n",
    "    while i < len(results[0]):\n",
    "        line = []\n",
    "        for num, ml in zip(results, mod_list): \n",
    "            line.append([num[i],ml])\n",
    "\n",
    "        i = i+1\n",
    "        df = df.append(pd.DataFrame(line, columns=['Score', 'ML']),ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boxplot = append_res_to_boxplot(results, df_boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>ML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709818</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.592648</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.564080</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643582</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.709291</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.697174</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.517241</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.575575</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.708429</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.720929</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.650335</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.567792</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.608980</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.627011</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.711111</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.712117</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.549928</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.563003</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.668247</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.731849</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.696999</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.494283</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.621345</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.716588</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.747660</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.722812</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.512882</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.586461</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.679268</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.701148</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.698784</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.471437</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.544944</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.685950</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.718035</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.679021</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.505208</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.588033</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.638106</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.694186</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.678343</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.466134</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.554021</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.708697</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.736579</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.695010</td>\n",
       "      <td>LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.536313</td>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.558188</td>\n",
       "      <td>DecTree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.672432</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.675339</td>\n",
       "      <td>XGB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Score       ML\n",
       "0   0.709818       LR\n",
       "1   0.592648      KNN\n",
       "2   0.564080  DecTree\n",
       "3   0.643582       RF\n",
       "4   0.709291      XGB\n",
       "5   0.697174       LR\n",
       "6   0.517241      KNN\n",
       "7   0.575575  DecTree\n",
       "8   0.708429       RF\n",
       "9   0.720929      XGB\n",
       "10  0.650335       LR\n",
       "11  0.567792      KNN\n",
       "12  0.608980  DecTree\n",
       "13  0.627011       RF\n",
       "14  0.711111      XGB\n",
       "15  0.712117       LR\n",
       "16  0.549928      KNN\n",
       "17  0.563003  DecTree\n",
       "18  0.668247       RF\n",
       "19  0.731849      XGB\n",
       "20  0.696999       LR\n",
       "21  0.494283      KNN\n",
       "22  0.621345  DecTree\n",
       "23  0.716588       RF\n",
       "24  0.747660      XGB\n",
       "25  0.722812       LR\n",
       "26  0.512882      KNN\n",
       "27  0.586461  DecTree\n",
       "28  0.679268       RF\n",
       "29  0.701148      XGB\n",
       "30  0.698784       LR\n",
       "31  0.471437      KNN\n",
       "32  0.544944  DecTree\n",
       "33  0.685950       RF\n",
       "34  0.718035      XGB\n",
       "35  0.679021       LR\n",
       "36  0.505208      KNN\n",
       "37  0.588033  DecTree\n",
       "38  0.638106       RF\n",
       "39  0.694186      XGB\n",
       "40  0.678343       LR\n",
       "41  0.466134      KNN\n",
       "42  0.554021  DecTree\n",
       "43  0.708697       RF\n",
       "44  0.736579      XGB\n",
       "45  0.695010       LR\n",
       "46  0.536313      KNN\n",
       "47  0.558188  DecTree\n",
       "48  0.672432       RF\n",
       "49  0.675339      XGB"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the results \n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title(\"Cross-validation 'roc_auc' score and various NAs cleaning approaches, Roc_Auc score\")\n",
    "sns.boxplot(data = df_boxplot, x = 'ML',y='Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relatively small grid of parameters due to time and computational resources limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'nthread':[12], \n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05, 0.06], \n",
    "              'max_depth': [7,8],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [1000], \n",
    "              'seed': [300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(xgb, grid, n_jobs=-1, \n",
    "                   cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  20 | elapsed: 19.5min remaining: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 31.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:46:14] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     miss...\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7],\n",
       "                         'learning_rate': [0.05, 0.06], 'max_depth': [7, 8],\n",
       "                         'min_child_weight': [11], 'n_estimators': [1000],\n",
       "                         'nthread': [12], 'objective': ['binary:logistic'],\n",
       "                         'seed': [300], 'silent': [1], 'subsample': [0.8]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.06,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 11,\n",
       " 'n_estimators': 1000,\n",
       " 'nthread': 12,\n",
       " 'objective': 'binary:logistic',\n",
       " 'seed': 300,\n",
       " 'silent': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation: GridSearchCV XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110052765029913"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5894803935369841"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7392900856793145"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[545,  61],\n",
       "       [152,  59]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reveived ROC_AUC Metrics are rather weak and require furhter finetuning and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling and averaging several models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model averaging with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=XGBClassifier(colsample_bytree=0.7,\n",
    "                  learning_rate=0.06,\n",
    "                  max_depth=8,\n",
    "                  min_child_weight=11,\n",
    "                  n_estimators=1000,\n",
    "                  objective='binary:logistic',\n",
    "                  seed=300,\n",
    "                  silent=1,\n",
    "                  subsample=0.8,\n",
    "                  tree_method='gpu_hist')\n",
    "clf2=XGBClassifier(colsample_bytree=0.7,\n",
    "                  learning_rate=0.06,\n",
    "                  max_depth=8,\n",
    "                  min_child_weight=11,\n",
    "                  n_estimators=1000,\n",
    "                  objective='binary:logistic',\n",
    "                  seed=600,\n",
    "                  silent=1,\n",
    "                  subsample=0.8,\n",
    "                  tree_method='gpu_hist')\n",
    "clf1=XGBClassifier(colsample_bytree=0.7,\n",
    "                  learning_rate=0.06,\n",
    "                  max_depth=8,\n",
    "                  min_child_weight=11,\n",
    "                  n_estimators=1000,\n",
    "                  objective='binary:logistic',\n",
    "                  seed=13,\n",
    "                  silent=1,\n",
    "                  subsample=0.8,\n",
    "                  tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:57:50] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:59:23] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:00:58] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf3 = clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = clf1.predict(X_test)\n",
    "prediction2 = clf2.predict(X_test)\n",
    "prediction3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_averaged = [np.round(np.mean([p1, p2, p3])) for p1,p2,p3 in zip(prediction1, prediction2, prediction3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC: 0.5887608903070402\n",
      "Accuracy score: 0.7405140758873929\n",
      "Confusion matrix: \n",
      " [[547  59]\n",
      " [153  58]]\n",
      "Precision score: 0.49572649572649574\n"
     ]
    }
   ],
   "source": [
    "print('ROC_AUC:', roc_auc_score(y_test, pred_averaged))\n",
    "print('Accuracy score:', accuracy_score(y_test, pred_averaged))\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_test, pred_averaged))\n",
    "print('Precision score:', precision_score(y_test, pred_averaged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84       606\n",
      "           1       0.50      0.27      0.35       211\n",
      "\n",
      "    accuracy                           0.74       817\n",
      "   macro avg       0.64      0.59      0.60       817\n",
      "weighted avg       0.71      0.74      0.71       817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_averaged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Averagind decrese ROC_AUC and slightly improve Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:05:51] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:07:24] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:08:59] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble=VotingClassifier(estimators=[('Clf1', clf1), ('Clf2', clf2), ('Clf3', clf3)], \n",
    "                       voting='soft').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC 0.5887608903070402\n",
      "Accuracy score 0.7405140758873929\n",
      "Confusion matrix [[547  59]\n",
      " [153  58]]\n"
     ]
    }
   ],
   "source": [
    "pred_vc = ensemble.predict(X_test)\n",
    "print('ROC_AUC', roc_auc_score(y_test, pred_vc))\n",
    "print('Accuracy score', accuracy_score(y_test, pred_vc))\n",
    "print('Confusion matrix', confusion_matrix(y_test, pred_vc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier gives no improvement comparing to the simple averaging of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = clf.predict_proba(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = pd.DataFrame()\n",
    "results_test['id'] = df_test_target['id']\n",
    "results_test['score'] = np.array(probability)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084</td>\n",
       "      <td>0.059249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4085</td>\n",
       "      <td>0.028981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4086</td>\n",
       "      <td>0.083604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4087</td>\n",
       "      <td>0.252466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4088</td>\n",
       "      <td>0.789893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>5101</td>\n",
       "      <td>0.381586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>5102</td>\n",
       "      <td>0.334630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>5103</td>\n",
       "      <td>0.212447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>5104</td>\n",
       "      <td>0.127899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>5105</td>\n",
       "      <td>0.023387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     score\n",
       "0     4084  0.059249\n",
       "1     4085  0.028981\n",
       "2     4086  0.083604\n",
       "3     4087  0.252466\n",
       "4     4088  0.789893\n",
       "...    ...       ...\n",
       "1017  5101  0.381586\n",
       "1018  5102  0.334630\n",
       "1019  5103  0.212447\n",
       "1020  5104  0.127899\n",
       "1021  5105  0.023387\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.to_csv('BateikoEduard_test.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_coursera",
   "language": "python",
   "name": "ml_coursera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
